# è®­ç»ƒ

æˆ‘ä»¬ç°åœ¨å‡†å¤‡ç¼–å†™åœ¨ MNIST æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹æ‰€éœ€çš„ä»£ç ã€‚æˆ‘ä»¬å°†åœ¨æ–‡ä»¶ `src/training.rs` ä¸­å®šä¹‰æ­¤è®­ç»ƒéƒ¨åˆ†çš„ä»£ç ã€‚

æ¨¡å‹åº”è¯¥è¾“å‡ºä¸€ä¸ªå¯ä»¥è¢«å­¦ä¹ å™¨ç†è§£çš„é¡¹ç›®ï¼Œè€Œä¸æ˜¯ç®€å•å¼ é‡ï¼Œå­¦ä¹ å™¨çš„èŒè´£æ˜¯å°†ä¼˜åŒ–å™¨åº”ç”¨äºæ¨¡å‹ã€‚è¾“å‡ºç»“æ„ä½“ç”¨äºè®­ç»ƒæœŸé—´è®¡ç®—çš„æ‰€æœ‰æŒ‡æ ‡ã€‚å› æ­¤ï¼Œå®ƒåº”åŒ…å«è®¡ç®—ä»»åŠ¡æ‰€éœ€æŒ‡æ ‡çš„æ‰€æœ‰å¿…è¦ä¿¡æ¯ã€‚

Burn æä¾›äº†ä¸¤ç§åŸºæœ¬è¾“å‡ºç±»å‹ï¼š`ClassificationOutput` å’Œ `RegressionOutput`ã€‚å®ƒä»¬å®ç°äº†ä¸æŒ‡æ ‡ä¸€èµ·ä½¿ç”¨çš„å¿…è¦ traitã€‚å¯ä»¥åˆ›å»ºè‡ªå·±çš„é¡¹ç›®ï¼Œä½†è¿™è¶…å‡ºäº†æœ¬æŒ‡å—çš„èŒƒå›´ã€‚

ç”±äº MNIST ä»»åŠ¡æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `ClassificationOutput` ç±»å‹ã€‚

```rust , ignore
# use crate::{
#     data::{MnistBatch, MnistBatcher},
#     model::{Model, ModelConfig},
# };
# use burn::{
#     data::{dataloader::DataLoaderBuilder, dataset::vision::MnistDataset},
#     nn::loss::CrossEntropyLossConfig,
#     optim::AdamConfig,
#     prelude::*,
#     record::CompactRecorder,
#     tensor::backend::AutodiffBackend,
#     train::{
#         metric::{AccuracyMetric, LossMetric},
#         ClassificationOutput, LearnerBuilder, TrainOutput, TrainStep, ValidStep,
#     },
# };
# 
impl<B: Backend> Model<B> {
    pub fn forward_classification(
        &self,
        images: Tensor<B, 3>,
        targets: Tensor<B, 1, Int>,
    ) -> ClassificationOutput<B> {
        let output = self.forward(images);
        let loss = CrossEntropyLossConfig::new()
            .init(&output.device())
            .forward(output.clone(), targets.clone());

        ClassificationOutput::new(loss, output, targets)
    }
}
```

ä»å‰é¢çš„ä»£ç å—ä¸­å¯ä»¥æ˜æ˜¾çœ‹å‡ºï¼Œæˆ‘ä»¬ä½¿ç”¨äº¤å‰ç†µæŸå¤±æ¨¡å—è¿›è¡ŒæŸå¤±è®¡ç®—ï¼Œä¸åŒ…æ‹¬ä»»ä½•å¡«å……æ ‡è®°ã€‚ç„¶åæˆ‘ä»¬è¿”å›åŒ…å«æŸå¤±ã€å¸¦æœ‰æ‰€æœ‰é€»è¾‘å€¼çš„è¾“å‡ºå¼ é‡å’Œç›®æ ‡çš„åˆ†ç±»è¾“å‡ºã€‚

è¯·æ³¨æ„ï¼Œå¼ é‡æ“ä½œæ¥æ”¶æ‹¥æœ‰çš„å¼ é‡ä½œä¸ºè¾“å…¥ã€‚è¦å¤šæ¬¡ä½¿ç”¨å¼ é‡ï¼Œæ‚¨éœ€è¦ä½¿ç”¨ `clone()` å‡½æ•°ã€‚ä¸ç”¨æ‹…å¿ƒï¼›è¿™ä¸ªè¿‡ç¨‹ä¸ä¼šæ¶‰åŠå®é™…å¤åˆ¶å¼ é‡æ•°æ®ã€‚ç›¸åï¼Œå®ƒåªä¼šè¡¨æ˜å¼ é‡åœ¨å¤šä¸ªå®ä¾‹ä¸­ä½¿ç”¨ï¼Œè¿™æ„å‘³ç€æŸäº›æ“ä½œä¸ä¼šå°±åœ°æ‰§è¡Œã€‚æ€»ä¹‹ï¼Œæˆ‘ä»¬çš„ API è®¾è®¡ä¸ºæ‹¥æœ‰å¼ é‡ä»¥ä¼˜åŒ–æ€§èƒ½ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ç»§ç»­å®ç°æ¨¡å‹çš„è®­ç»ƒå’ŒéªŒè¯æ­¥éª¤ã€‚

```rust , ignore
# use crate::{
#     data::{MnistBatch, MnistBatcher},
#     model::{Model, ModelConfig},
# };
# use burn::{
#     data::{dataloader::DataLoaderBuilder, dataset::vision::MnistDataset},
#     nn::loss::CrossEntropyLossConfig,
#     optim::AdamConfig,
#     prelude::*,
#     record::CompactRecorder,
#     tensor::backend::AutodiffBackend,
#     train::{
#         metric::{AccuracyMetric, LossMetric},
#         ClassificationOutput, LearnerBuilder, TrainOutput, TrainStep, ValidStep,
#     },
# };
# 
# impl<B: Backend> Model<B> {
#     pub fn forward_classification(
#         &self,
#         images: Tensor<B, 3>,
#         targets: Tensor<B, 1, Int>,
#     ) -> ClassificationOutput<B> {
#         let output = self.forward(images);
#         let loss = CrossEntropyLossConfig::new()
#             .init(&output.device())
#             .forward(output.clone(), targets.clone());
# 
#         ClassificationOutput::new(loss, output, targets)
#     }
# }
# 
impl<B: AutodiffBackend> TrainStep<MnistBatch<B>, ClassificationOutput<B>> for Model<B> {
    fn step(&self, batch: MnistBatch<B>) -> TrainOutput<ClassificationOutput<B>> {
        let item = self.forward_classification(batch.images, batch.targets);

        TrainOutput::new(self, item.loss.backward(), item)
    }
}

impl<B: Backend> ValidStep<MnistBatch<B>, ClassificationOutput<B>> for Model<B> {
    fn step(&self, batch: MnistBatch<B>) -> ClassificationOutput<B> {
        self.forward_classification(batch.images, batch.targets)
    }
}
```

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åœ¨ `TrainStep` å’Œ `ValidStep` ä¸­å°†è¾“å…¥å’Œè¾“å‡ºç±»å‹å®šä¹‰ä¸ºæ³›å‹å‚æ•°ã€‚æˆ‘ä»¬å°†å®ƒä»¬ç§°ä¸º `MnistBatch` å’Œ `ClassificationOutput`ã€‚åœ¨è®­ç»ƒæ­¥éª¤ä¸­ï¼Œæ¢¯åº¦çš„è®¡ç®—å¾ˆç®€å•ï¼Œåªéœ€åœ¨æŸå¤±ä¸Šè°ƒç”¨ `backward()`ã€‚è¯·æ³¨æ„ï¼Œä¸ PyTorch ä¸åŒï¼Œæ¢¯åº¦ä¸å­˜å‚¨åœ¨æ¯ä¸ªå¼ é‡å‚æ•°æ—è¾¹ï¼Œè€Œæ˜¯ç”±åå‘ä¼ é€’è¿”å›ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š`let gradients = loss.backward();`ã€‚å¯ä»¥ä½¿ç”¨ grad å‡½æ•°è·å¾—å‚æ•°çš„æ¢¯åº¦ï¼š`let grad = tensor.grad(&gradients);`ã€‚è™½ç„¶åœ¨ä½¿ç”¨å­¦ä¹ å™¨ç»“æ„ä½“å’Œä¼˜åŒ–å™¨æ—¶ä¸éœ€è¦è¿™æ ·åšï¼Œä½†åœ¨è°ƒè¯•æˆ–ç¼–å†™è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯æ—¶ï¼Œè¿™å¯èƒ½éå¸¸æœ‰ç”¨ã€‚è®­ç»ƒæ­¥éª¤å’ŒéªŒè¯æ­¥éª¤ä¹‹é—´çš„ä¸€ä¸ªåŒºåˆ«æ˜¯ï¼Œå‰è€…è¦æ±‚åç«¯å®ç° `AutodiffBackend` è€Œä¸ä»…ä»…æ˜¯ `Backend`ã€‚å¦åˆ™ï¼Œ`backward` å‡½æ•°ä¸å¯ç”¨ï¼Œå› ä¸ºåç«¯ä¸æ”¯æŒè‡ªåŠ¨å¾®åˆ†ã€‚ç¨åæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•åˆ›å»ºæ”¯æŒè‡ªåŠ¨å¾®åˆ†çš„åç«¯ã€‚

<details>
<summary><strong>ğŸ¦€ æ–¹æ³•å®šä¹‰ä¸­çš„æ³›å‹ç±»å‹çº¦æŸ</strong></summary>

å°½ç®¡åœ¨æœ¬æŒ‡å—çš„å‰é¢éƒ¨åˆ†å·²ç»ä»‹ç»äº†æ³›å‹æ•°æ®ç±»å‹ã€trait å’Œ trait è¾¹ç•Œï¼Œä½†å‰é¢çš„ä»£ç ç‰‡æ®µå¯èƒ½ä¸€å¼€å§‹çœ‹èµ·æ¥å¾ˆå¤šã€‚

åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä¸º `Model` ç»“æ„ä½“å®ç°äº† `TrainStep` å’Œ `ValidStep` traitï¼Œå®ƒåœ¨ `Backend` trait ä¸Šæ˜¯æ³›å‹çš„ï¼Œå¦‚å‰æ‰€è¿°ã€‚è¿™äº› trait ç”± `burn::train` æä¾›ï¼Œå®šä¹‰äº†åº”è¯¥ä¸ºæ‰€æœ‰ç»“æ„ä½“å®ç°çš„é€šç”¨ `step` æ–¹æ³•ã€‚ç”±äº trait åœ¨è¾“å…¥å’Œè¾“å‡ºç±»å‹ä¸Šæ˜¯æ³›å‹çš„ï¼Œtrait å®ç°å¿…é¡»æŒ‡å®šä½¿ç”¨çš„å…·ä½“ç±»å‹ã€‚è¿™å°±æ˜¯é¢å¤–ç±»å‹çº¦æŸå‡ºç°çš„åœ°æ–¹ `<MnistBatch<B>, ClassificationOutput<B>>`ã€‚æ­£å¦‚æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„ï¼Œæ‰¹å¤„ç†çš„å…·ä½“è¾“å…¥ç±»å‹æ˜¯ `MnistBatch`ï¼Œå‰å‘ä¼ é€’çš„è¾“å‡ºæ˜¯ `ClassificationOutput`ã€‚`step` æ–¹æ³•ç­¾åä¸å…·ä½“è¾“å…¥å’Œè¾“å‡ºç±»å‹åŒ¹é…ã€‚

æœ‰å…³å®šä¹‰æ–¹æ³•æ—¶æ³›å‹ç±»å‹çº¦æŸçš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ Rust Book çš„[è¿™ä¸€éƒ¨åˆ†](https://doc.rust-lang.org/book/ch10-01-syntax.html#in-method-definitions)ã€‚

</details><br>

è®©æˆ‘ä»¬ç»§ç»­å»ºç«‹å®é™…çš„è®­ç»ƒé…ç½®ã€‚

```rust , ignore
# use crate::{
#     data::{MnistBatch, MnistBatcher},
#     model::{Model, ModelConfig},
# };
# use burn::{
#     data::{dataloader::DataLoaderBuilder, dataset::vision::MnistDataset},
#     nn::loss::CrossEntropyLossConfig,
#     optim::AdamConfig,
#     prelude::*,
#     record::CompactRecorder,
#     tensor::backend::AutodiffBackend,
#     train::{
#         metric::{AccuracyMetric, LossMetric},
#         ClassificationOutput, LearnerBuilder, TrainOutput, TrainStep, ValidStep,
#     },
# };
# 
# impl<B: Backend> Model<B> {
#     pub fn forward_classification(
#         &self,
#         images: Tensor<B, 3>,
#         targets: Tensor<B, 1, Int>,
#     ) -> ClassificationOutput<B> {
#         let output = self.forward(images);
#         let loss = CrossEntropyLossConfig::new()
#             .init(&output.device())
#             .forward(output.clone(), targets.clone());
# 
#         ClassificationOutput::new(loss, output, targets)
#     }
# }
# 
# impl<B: AutodiffBackend> TrainStep<MnistBatch<B>, ClassificationOutput<B>> for Model<B> {
#     fn step(&self, batch: MnistBatch<B>) -> TrainOutput<ClassificationOutput<B>> {
#         let item = self.forward_classification(batch.images, batch.targets);
# 
#         TrainOutput::new(self, item.loss.backward(), item)
#     }
# }
# 
# impl<B: Backend> ValidStep<MnistBatch<B>, ClassificationOutput<B>> for Model<B> {
#     fn step(&self, batch: MnistBatch<B>) -> ClassificationOutput<B> {
#         self.forward_classification(batch.images, batch.targets)
#     }
# }
# 
#[derive(Config)]
pub struct TrainingConfig {
    pub model: ModelConfig,
    pub optimizer: AdamConfig,
    #[config(default = 10)]
    pub num_epochs: usize,
    #[config(default = 64)]
    pub batch_size: usize,
    #[config(default = 4)]
    pub num_workers: usize,
    #[config(default = 42)]
    pub seed: u64,
    #[config(default = 1.0e-4)]
    pub learning_rate: f64,
}

fn create_artifact_dir(artifact_dir: &str) {
    // åœ¨è·å–å‡†ç¡®çš„å­¦ä¹ å™¨æ‘˜è¦ä¹‹å‰åˆ é™¤ç°æœ‰å·¥ä»¶
    std::fs::remove_dir_all(artifact_dir).ok();
    std::fs::create_dir_all(artifact_dir).ok();
}

pub fn train<B: AutodiffBackend>(artifact_dir: &str, config: TrainingConfig, device: B::Device) {
    create_artifact_dir(artifact_dir);
    config
        .save(format!("{artifact_dir}/config.json"))
        .expect("é…ç½®åº”è¯¥æˆåŠŸä¿å­˜");

    B::seed(config.seed);

    let batcher = MnistBatcher::default();

    let dataloader_train = DataLoaderBuilder::new(batcher.clone())
        .batch_size(config.batch_size)
        .shuffle(config.seed)
        .num_workers(config.num_workers)
        .build(MnistDataset::train());

    let dataloader_test = DataLoaderBuilder::new(batcher)
        .batch_size(config.batch_size)
        .shuffle(config.seed)
        .num_workers(config.num_workers)
        .build(MnistDataset::test());

    let learner = LearnerBuilder::new(artifact_dir)
        .metric_train_numeric(AccuracyMetric::new())
        .metric_valid_numeric(AccuracyMetric::new())
        .metric_train_numeric(LossMetric::new())
        .metric_valid_numeric(LossMetric::new())
        .with_file_checkpointer(CompactRecorder::new())
        .devices(vec![device.clone()])
        .num_epochs(config.num_epochs)
        .summary()
        .build(
            config.model.init::<B>(&device),
            config.optimizer.init(),
            config.learning_rate,
        );

    let model_trained = learner.fit(dataloader_train, dataloader_test);

    model_trained
        .save_file(format!("{artifact_dir}/model"), &CompactRecorder::new())
        .expect("è®­ç»ƒæ¨¡å‹åº”è¯¥æˆåŠŸä¿å­˜");
}
```

ä½¿ç”¨ `Config` derive åˆ›å»ºå®éªŒé…ç½®æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ã€‚åœ¨ `train` å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆè¦ç¡®ä¿ `artifact_dir` å­˜åœ¨ï¼Œä½¿ç”¨æ ‡å‡† rust åº“è¿›è¡Œæ–‡ä»¶æ“ä½œã€‚æ‰€æœ‰æ£€æŸ¥ç‚¹ã€æ—¥å¿—å’ŒæŒ‡æ ‡éƒ½å°†å­˜å‚¨åœ¨æ­¤ç›®å½•ä¸‹ã€‚æˆ‘ä»¬ä½¿ç”¨ä¹‹å‰åˆ›å»ºçš„æ‰¹å¤„ç†å™¨åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨ã€‚ç”±äºåœ¨éªŒè¯é˜¶æ®µä¸éœ€è¦è‡ªåŠ¨å¾®åˆ†ï¼Œ`learner.fit(...)` æ–¹æ³•ä¸ºæ•°æ®åŠ è½½å™¨å®šä¹‰äº† `B::InnerBackend` çš„å¿…è¦åç«¯è¾¹ç•Œï¼ˆå‚è§[åç«¯](./backend.md)ï¼‰ã€‚è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½é€šè¿‡ç±»å‹ç³»ç»Ÿæä¾›ï¼Œä½¿å¾—å‡ ä¹ä¸å¯èƒ½å¿˜è®°åœç”¨æ¢¯åº¦è®¡ç®—ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºå­¦ä¹ å™¨ï¼Œåœ¨è®­ç»ƒå’ŒéªŒè¯æ­¥éª¤ä¸­éƒ½åŒ…å«å‡†ç¡®ç‡å’ŒæŸå¤±æŒ‡æ ‡ï¼Œä»¥åŠè®¾å¤‡å’Œå‘¨æœŸã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨ `CompactRecorder` é…ç½®æ£€æŸ¥ç‚¹ï¼Œä»¥æŒ‡ç¤ºæƒé‡åº”å¦‚ä½•å­˜å‚¨ã€‚è¿™ä¸ªç»“æ„ä½“å®ç°äº† `Recorder` traitï¼Œä½¿å…¶èƒ½å¤Ÿä¿å­˜è®°å½•ä»¥å®ç°æŒä¹…æ€§ã€‚

ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨æ¨¡å‹ã€ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡æ„å»ºå­¦ä¹ å™¨ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ„å»ºå‡½æ•°çš„ç¬¬ä¸‰ä¸ªå‚æ•°å®é™…ä¸Šåº”è¯¥æ˜¯ä¸€ä¸ªå­¦ä¹ ç‡ _è°ƒåº¦å™¨_ã€‚åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­æä¾›æµ®ç‚¹æ•°æ—¶ï¼Œå®ƒä¼šè‡ªåŠ¨è½¬æ¢ä¸º _å¸¸æ•°_ å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚å­¦ä¹ ç‡ä¸æ˜¯ä¼˜åŒ–å™¨é…ç½®çš„ä¸€éƒ¨åˆ†ï¼Œè¿™ä¸å…¶ä»–æ¡†æ¶ä¸­çš„åšæ³•ä¸åŒï¼Œè€Œæ˜¯åœ¨æ‰§è¡Œä¼˜åŒ–å™¨æ­¥éª¤æ—¶ä½œä¸ºå‚æ•°ä¼ é€’ã€‚è¿™é¿å…äº†å¿…é¡»æ”¹å˜ä¼˜åŒ–å™¨çš„çŠ¶æ€ï¼Œå› æ­¤æ›´åŠ å‡½æ•°å¼ã€‚åœ¨ä½¿ç”¨å­¦ä¹ å™¨ç»“æ„ä½“æ—¶æ²¡æœ‰åŒºåˆ«ï¼Œä½†å¦‚æœæ‚¨å®ç°è‡ªå·±çš„è®­ç»ƒå¾ªç¯ï¼Œè¿™å°†æ˜¯ä¸€ä¸ªå¿…é¡»æŒæ¡çš„é‡è¦ç»†å¾®å·®åˆ«ã€‚

ä¸€æ—¦åˆ›å»ºäº†å­¦ä¹ å™¨ï¼Œæˆ‘ä»¬å°±å¯ä»¥ç®€å•åœ°è°ƒç”¨ `fit` å¹¶æä¾›è®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨ã€‚ä¸ºäº†ç®€åŒ–æ­¤ç¤ºä¾‹ï¼Œæˆ‘ä»¬ä½¿ç”¨æµ‹è¯•é›†ä½œä¸ºéªŒè¯é›†ï¼›ä½†æ˜¯ï¼Œæˆ‘ä»¬ä¸å»ºè®®åœ¨å®é™…ä½¿ç”¨ä¸­é‡‡ç”¨è¿™ç§åšæ³•ã€‚

æœ€åï¼Œè®­ç»ƒå¥½çš„æ¨¡å‹ç”± `fit` æ–¹æ³•è¿”å›ã€‚ç„¶åä½¿ç”¨ `CompactRecorder` ä¿å­˜è®­ç»ƒå¥½çš„æƒé‡ã€‚è¿™ä¸ªè®°å½•å™¨ä½¿ç”¨ `MessagePack` æ ¼å¼ï¼Œæµ®ç‚¹æ•°ä¸ºåŠç²¾åº¦ `f16`ï¼Œæ•´æ•°ä¸º `i16`ã€‚è¿˜æœ‰å…¶ä»–è®°å½•å™¨å¯ç”¨ï¼Œæ”¯æŒå„ç§æ ¼å¼ï¼Œå¦‚ `BinCode` å’Œ `JSON`ï¼Œæœ‰æˆ–æ²¡æœ‰å‹ç¼©ã€‚ä»»ä½•åç«¯ï¼Œæ— è®ºç²¾åº¦å¦‚ä½•ï¼Œéƒ½å¯ä»¥åŠ è½½ä»»ä½•ç±»å‹çš„è®°å½•æ•°æ®ã€‚